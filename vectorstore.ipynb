{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\Other computers\\My Computer\\Work\\LLM\\llm\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "import ollama\n",
    "import chromadb\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "from chromadb.utils import embedding_functions\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "docdir='H:/Other computers/My Computer/Work/LLM/rag_docs/'\n",
    "dbdir='C:/Users/Renhwai/Documents/Local Projects/vectorstore/'\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023 Feb Data Analyst Resume.docx.pdf\n",
      "which are the technical tools that you have used for analysis and presentation purposes\n",
      "what are the best methods for data cleaning\n",
      "explain descriptive, predictive, and prescriptive analytics\n",
      "what are some common data visualization tools you have used\n",
      "how can you handle missing values in a dataset\n",
      "what is Time Series analysis\n",
      "what is Overfitting\n",
      "why should we hire you\n",
      "please share about your data analysis projects from your past working experience\n",
      "please share about your development projects\n",
      "what are your strengths and weaknesses as a data analyst\n"
     ]
    }
   ],
   "source": [
    "for i in os.listdir(docdir):\n",
    "    print(i.replace('.txt',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsplit=TextLoader(docdir+'Job descriptions of opening position shared by Hiring Manager.txt').load_and_split(text_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_client_collection(dbdir,collectioname):\n",
    "    sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"all-mpnet-base-v2\")\n",
    "    chroma_client=chromadb.PersistentClient(path=dbdir+collectioname)\n",
    "    return chroma_client,chroma_client.create_collection(name=collectioname, embedding_function=sentence_transformer_ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client1,collection1=create_client_collection(dbdir,'collection1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf=PyPDFLoader(docdir+'2023 Feb Data Analyst Resume.docx.pdf').load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content=\"KONG REN HW AI (Mr .)\\nSUMMARY\\nA skilled and experienced process engineer with 7 years in the \\nSemiconductor Industry. Achieved a Bachelor's Degree in Materials \\nEngineering with First Class Honours and completed Google Data Analytics \\ncertiﬁcation\\n(\\nlink\\n)\\n.\\nProﬁcient in big data analytics, agile project management, and data analysis \\ntechniques. Seeking new opportunities in Big Data Analytics and AI \\ninnovation.\\nWORK EXPERIENCE\\nMicron Singapore Backend, Singapore\", metadata={'source': 'H:/Other computers/My Computer/Work/LLM/rag_docs/2023 Feb Data Analyst Resume.docx.pdf', 'page': 0}), Document(page_content='innovation.\\nWORK EXPERIENCE\\nMicron Singapore Backend, Singapore\\nSenior Industry 4.0 Analyst  (March 2022 -\\nPresent)\\n●\\nManage stakeholder expectations and user requirements from VP, director and engineer\\n●\\nLed projects in Tool Alarm KPI Management, Virtual Metrology, Fault Detection Control & \\nPredictive Maintenance\\n●\\nTrained in Jira, Snowﬂake, Bigquery, Spotﬁre and Tableau\\nSenior Package Development Engineer (Wire Bond)\\n(March 2018 - March 2022)\\n●', metadata={'source': 'H:/Other computers/My Computer/Work/LLM/rag_docs/2023 Feb Data Analyst Resume.docx.pdf', 'page': 0}), Document(page_content='Senior Package Development Engineer (Wire Bond)\\n(March 2018 - March 2022)\\n●\\nConducted Technical Risk Assessment (TRA) for new wafer and package technology\\n●\\nConducted pathﬁnding research for new products and technologies\\nAssembly New Product Introduction Engineer (Wire Bond)  (Sep 2016 - Mar 2018)\\n●\\nGenerate new wire bond recipes to support customer and NPI qualiﬁcation\\n●\\nOwner for low volume run (LVR) KPIs for yield, cycle time and quality', metadata={'source': 'H:/Other computers/My Computer/Work/LLM/rag_docs/2023 Feb Data Analyst Resume.docx.pdf', 'page': 0}), Document(page_content='●\\nOwner for low volume run (LVR) KPIs for yield, cycle time and quality\\nAssembly Process Engineer (Wire Bond)  (Jul 2015 - Sep 2016)\\n●\\nMonitor weekly high volume manufacturing (HVM) for yield, cycle time, quality and output\\nEDUCATION\\n1.\\nBachelor of Materials Engineering\\nNanyang Technological University, Singapore\\n. G\\nraduate\\nin 2015 June\\n●\\nFirst Class Honours, CGPA: 4.58\\n2.\\nDiploma in Nanotechnology and Materials Science\\nNanyang Polytechnic, Singapore. Graduated in 2012 April\\n●', metadata={'source': 'H:/Other computers/My Computer/Work/LLM/rag_docs/2023 Feb Data Analyst Resume.docx.pdf', 'page': 0}), Document(page_content='Nanyang Polytechnic, Singapore. Graduated in 2012 April\\n●\\nBronze Medalist, Diploma with Merit\\n●\\nPresident of Astronomy Club & Executive Committee of School of Engineering Club\\nP age1of2', metadata={'source': 'H:/Other computers/My Computer/Work/LLM/rag_docs/2023 Feb Data Analyst Resume.docx.pdf', 'page': 0}), Document(page_content='SKILLS & ABILITY\\nAgile Project Management\\n: Experience with agile & waterfall hybrid project management \\nusing Jira and Conﬂuence\\nBig Data and Database\\n: Proﬁcient in basic SQL, Snowﬂake, Bigquery, Spotﬁre and Tableau\\nData Analysis\\n:  Familiar in source of variation and factor correlation study for \\nroot cause ﬁnding and Measurement System Analysis (MSA)\\nDesign of Experiment (DOE)\\n: Completed JMP Classical and Custom DOE courses. Certiﬁed as \\nCompany DOE Trainer', metadata={'source': 'H:/Other computers/My Computer/Work/LLM/rag_docs/2023 Feb Data Analyst Resume.docx.pdf', 'page': 1}), Document(page_content=': Completed JMP Classical and Custom DOE courses. Certiﬁed as \\nCompany DOE Trainer\\nKepner Tregoe (KT) Problem Solving\\n: Complete KT training with a certiﬁed trainer, utilizing logical \\nthinking and data analysis to analyze root cause and perform risk \\nassessment\\nMicrosoft Sharepoint\\n: Owner of department collaboration site. Responsible for KPI \\nreporting, project tracking, document permission & retention \\ncontrol\\nStatiscal Process Control (SPC)', metadata={'source': 'H:/Other computers/My Computer/Work/LLM/rag_docs/2023 Feb Data Analyst Resume.docx.pdf', 'page': 1}), Document(page_content='control\\nStatiscal Process Control (SPC)\\n: Process SPC owner during HVM and NPI. FMEA champion\\n8D Problem Solving and Reporting\\n: Experienced with 8D report requirements for internal and external \\ncustomers\\nPERSONAL INFORMATION\\nWork Pass Status\\n: Singapore Permanent Resident\\nSingapore Address\\n: #04-20, 11 Yio Chu Kang Road, Singapore 545679\\nLanguage Proﬁciency\\n: English (advanced), Mandarin (advanced), Malay (elemental)\\nContact Number\\n: (65) 81592786\\nEmail Address\\n:\\nkongrenhwai@hotmail.com', metadata={'source': 'H:/Other computers/My Computer/Work/LLM/rag_docs/2023 Feb Data Analyst Resume.docx.pdf', 'page': 1}), Document(page_content='Contact Number\\n: (65) 81592786\\nEmail Address\\n:\\nkongrenhwai@hotmail.com\\nLinkedIn Proﬁle\\n:\\nhttps://www.linkedin.com/in/renhwai-kong-4ba6a389/\\nP age2of2', metadata={'source': 'H:/Other computers/My Computer/Work/LLM/rag_docs/2023 Feb Data Analyst Resume.docx.pdf', 'page': 1})]\n"
     ]
    }
   ],
   "source": [
    "chunk = text_splitter.split_documents(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in chunk:\n",
    "    print(i.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_docfolder2(db_collection,folderpath):\n",
    "        print(db_collection,'is generating...')\n",
    "        id=[]\n",
    "        index=0\n",
    "        for i in os.listdir(folderpath):\n",
    "            if i.endswith(\".txt\") and i!='Job descriptions of opening position shared by Hiring Manager.txt':\n",
    "                txt=TextLoader(folderpath+i,encoding='utf8').load_and_split(text_splitter)\n",
    "                #txt=TextLoader(folderpath+i).load()\n",
    "                topic=i.replace(\".txt\",\"\")\n",
    "                for chunk in txt:\n",
    "                    id=[str(index)]\n",
    "                    db_collection.add(\n",
    "                    documents=chunk.page_content,\n",
    "                    metadatas=[{\"topic\":topic,'source':chunk.metadata['source']}],\n",
    "                    ids=id\n",
    "                    )\n",
    "                    index=index+1\n",
    "                print(i,\"is added.\")\n",
    "                \n",
    "            if i.endswith(\".txt\") and i=='Job descriptions of opening position shared by Hiring Manager.txt':\n",
    "                txt=TextLoader(folderpath+i,encoding='utf8').load_and_split(text_splitter)\n",
    "                #txt=TextLoader(folderpath+i).load()\n",
    "                topic=i.replace(\".txt\",\"\")\n",
    "                for chunk in txt:\n",
    "                    id=['-'+str(index)]\n",
    "                    db_collection.add(\n",
    "                    documents=chunk.page_content,\n",
    "                    metadatas=[{\"topic\":topic,'source':chunk.metadata['source']}],\n",
    "                    ids=id\n",
    "                    )\n",
    "                    index=index+1\n",
    "                print(i,\"is added.\")\n",
    "                \n",
    "            if i.endswith(\".pdf\"):\n",
    "                pdf=PyPDFLoader(folderpath+i).load()\n",
    "                chunk = text_splitter.split_documents(pdf)\n",
    "                topic=i.replace(\".pdf\",\"\")\n",
    "                for j in chunk:\n",
    "                    id=[str(index)]\n",
    "                    db_collection.add(\n",
    "                    documents=j.page_content,\n",
    "                    metadatas=[{\"topic\":topic,'source':j.metadata['source']}],\n",
    "                    ids=id\n",
    "                    )\n",
    "                    index=index+1\n",
    "                print(i,\"is added.\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='collection1' id=UUID('d48ef7d8-5655-406b-8ecc-80299ea8f19e') metadata=None tenant='default_tenant' database='default_database' is generating...\n",
      "2023 Feb Data Analyst Resume.docx.pdf is added.\n",
      "which are the technical tools that you have used for analysis and presentation purposes.txt is added.\n",
      "what are the best methods for data cleaning.txt is added.\n",
      "explain descriptive, predictive, and prescriptive analytics.txt is added.\n",
      "what are some common data visualization tools you have used.txt is added.\n",
      "how can you handle missing values in a dataset.txt is added.\n",
      "what is Time Series analysis.txt is added.\n",
      "what is Overfitting.txt is added.\n",
      "why should we hire you.txt is added.\n",
      "please share about your data analysis projects from your past working experience.txt is added.\n",
      "please share about your development projects.txt is added.\n",
      "what are your strengths and weaknesses as a data analyst.txt is added.\n"
     ]
    }
   ],
   "source": [
    "update_docfolder2(collection1,docdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_docfolder(db_collection,folderpath):\n",
    "        print(db_collection,'is generating...')\n",
    "        id=[]\n",
    "        index=0\n",
    "        for i in os.listdir(folderpath):\n",
    "            if i.endswith(\".txt\") and i!='Job descriptions of opening position shared by Hiring Manager.txt':\n",
    "                txt=TextLoader(folderpath+i).load()\n",
    "                q=i.replace(\".txt\",\"\")\n",
    "                id=[str(index)]\n",
    "                db_collection.add(\n",
    "                documents=txt[0].page_content,\n",
    "                metadatas=[{\"topic\":q,'source':txt[0].metadata['source']}],\n",
    "                ids=id\n",
    "                )\n",
    "                print(q,\"is added.\")\n",
    "                index=index+1\n",
    "            if i.endswith(\".txt\") and i=='Job descriptions of opening position shared by Hiring Manager.txt':\n",
    "                txt=TextLoader(folderpath+i).load()\n",
    "                #id=[str(index)]\n",
    "                q=i.replace(\".txt\",\"\")\n",
    "                db_collection.add(\n",
    "                documents=txt[0].page_content,\n",
    "                metadatas=[{\"topic\":q,'source':txt[0].metadata['source']}],\n",
    "                ids=\"-1\"\n",
    "                )\n",
    "                print(q,\"is added.\")\n",
    "                #index=index+1\n",
    "            if i.endswith(\".pdf\"):\n",
    "                pdf=PyPDFLoader(docdir+i).load()\n",
    "                chunk = text_splitter.split_documents(pdf)\n",
    "                for j in chunk:\n",
    "                    id=[str(index)]\n",
    "                    q=i.replace(\".pdf\",\"\")\n",
    "                    db_collection.add(\n",
    "                    documents=chunk[0].page_content,\n",
    "                    metadatas=[{\"topic\":q,'source':chunk[0].metadata['source']}],\n",
    "                    ids=id\n",
    "                    )\n",
    "                    print(q,\"is added.\")\n",
    "                    index=index+1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_docfolder(collection,docdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbclient=chromadb.PersistentClient(path=\"H:/Other computers/My Computer/Work/LLM/vectorstore/collection8\")\n",
    "#sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"all-mpnet-base-v2\")\n",
    "#db10=dbclient.get_collection(name='collection4', embedding_function=sentence_transformer_ef)\n",
    "vectorstore = Chroma(\n",
    "    client=dbclient,\n",
    "    collection_name=\"collection8\",\n",
    "    embedding_function=SentenceTransformerEmbeddings(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hiring Manager asks, please share about your data analysis projects from your past working experience. The answer is, during my time as a Senior Industrial 4.0 Analyst at Micron Semiconductor, I successfully managed smart manufacturing projects focused on smart manufacturing and digital transformation. Here are a few examples:\n"
     ]
    }
   ],
   "source": [
    "print(vectorstore.similarity_search('What did the manager ask?')[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt=TextLoader('H:/Other computers/My Computer/Work/LLM/rag_docs/Job descriptions of opening position shared by Hiring Manager.txt').load()\n",
    "vectorstore.update_document(\n",
    "    document_id=\"-1\",\n",
    "    document=txt[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Hiring Manager from Klook seeks a Data Analyst with at least 4 years of experience in data analysis, data modeling, and understanding intricate business processes. The ideal candidate possesses strong technical skills in SQL, data querying languages, and data visualization tools. They must have excellent communication skills and experience collaborating with cross-functional teams. The role involves analyzing business requirements, documenting and scrutinizing business processes, and creating data models. The successful candidate will play a crucial role in driving Klook's data-driven initiatives and ensuring the success of data-driven products and services.\", metadata={'source': 'H:/Other computers/My Computer/Work/LLM/rag_docs/Job descriptions of opening position shared by Hiring Manager.txt', 'topic': 'Job descriptions of opening position shared by Hiring Manager'}),\n",
       " Document(page_content=\"Hiring Manager asks question, what are your strengths and weaknesses as a data analyst? The answer is, one of my strengths is, I excel at consolidating existing resources and thinking outside the box. I believe data analysis goes beyond just analyzing data; it's about presenting insights and transforming them into actionable plans. I actively seek out additional data sources and techniques beyond initial project requirements. Other than that, I emphasize on communication and collaboration, ensuring stakeholders receive a comprehensive view. I readily collaborate with other teams to identify user needs and explore possibilities like building dashboards or automating data access. Lastly, I think I have an edge over other data specialist in domain expertise. My diverse background in engineering, manufacturing, and finance allows me to assist other data specialists with troubleshooting and hypothesis generation. For my weakness, I believe I have to focs on developing programming skills. I am actively working to improve my programming skills, particularly in Python. While I have a basic understanding of Python, Google Cloud Platform, BigQuery, Snowflake, Jira, Streamlit, and Tableau, I sometimes rely on online resources to complete complex coding tasks. This can lead to longer completion times. However, I am a quick learner and highly motivated to overcome this limitation through dedicated learning and on-the-job training.\", metadata={'source': 'H:/Other computers/My Computer/Work/LLM/rag_docs/what are your strengths and weaknesses as a data analyst.txt', 'topic': 'what are your strengths and weaknesses as a data analyst'}),\n",
       " Document(page_content=\"KONG REN HW AI (Mr .)\\nSUMMARY\\nA skilled and experienced process engineer with 7 years in the \\nSemiconductor Industry. Achieved a Bachelor's Degree in Materials \\nEngineering with First Class Honours and completed Google Data Analytics \\ncertiﬁcation\\n(\\nlink\\n)\\n.\\nProﬁcient in big data analytics, agile project management, and data analysis \\ntechniques. Seeking new opportunities in Big Data Analytics and AI \\ninnovation.\\nWORK EXPERIENCE\\nMicron Singapore Backend, Singapore\\nSenior Industry 4.0 Analyst  (March 2022 -\\nPresent)\\n●\\nManage stakeholder expectations and user requirements from VP, director and engineer\\n●\\nLed projects in Tool Alarm KPI Management, Virtual Metrology, Fault Detection Control & \\nPredictive Maintenance\\n●\\nTrained in Jira, Snowﬂake, Bigquery, Spotﬁre and Tableau\\nSenior Package Development Engineer (Wire Bond)\\n(March 2018 - March 2022)\\n●\\nConducted Technical Risk Assessment (TRA) for new wafer and package technology\\n●\", metadata={'source': 'H:/Other computers/My Computer/Work/LLM/rag_docs/2023 Feb Data Analyst Resume.docx.pdf', 'topic': '2023 Feb Data Analyst Resume.docx'}),\n",
       " Document(page_content=\"KONG REN HW AI (Mr .)\\nSUMMARY\\nA skilled and experienced process engineer with 7 years in the \\nSemiconductor Industry. Achieved a Bachelor's Degree in Materials \\nEngineering with First Class Honours and completed Google Data Analytics \\ncertiﬁcation\\n(\\nlink\\n)\\n.\\nProﬁcient in big data analytics, agile project management, and data analysis \\ntechniques. Seeking new opportunities in Big Data Analytics and AI \\ninnovation.\\nWORK EXPERIENCE\\nMicron Singapore Backend, Singapore\\nSenior Industry 4.0 Analyst  (March 2022 -\\nPresent)\\n●\\nManage stakeholder expectations and user requirements from VP, director and engineer\\n●\\nLed projects in Tool Alarm KPI Management, Virtual Metrology, Fault Detection Control & \\nPredictive Maintenance\\n●\\nTrained in Jira, Snowﬂake, Bigquery, Spotﬁre and Tableau\\nSenior Package Development Engineer (Wire Bond)\\n(March 2018 - March 2022)\\n●\\nConducted Technical Risk Assessment (TRA) for new wafer and package technology\\n●\", metadata={'source': 'H:/Other computers/My Computer/Work/LLM/rag_docs/2023 Feb Data Analyst Resume.docx.pdf', 'topic': '2023 Feb Data Analyst Resume.docx'})]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.similarity_search('Tell me about this job description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description=\"\"\"Senior Data Analyst\n",
    "About Agoda\n",
    "\n",
    "Agoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 3.6 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enhancing the ability for our customers to experience the world.\n",
    "\n",
    " Our Purpose –  Bridging the World Through Travel \n",
    "\n",
    "We believe travel allows people to enjoy, learn and experience more of the amazing world we live in. It brings individuals and cultures closer together, fostering empathy, understanding and happiness.\n",
    "\n",
    "We are a skillful, driven and diverse team from across the globe, united by a passion to make an impact. Harnessing our innovative technologies and strong partnerships, we aim to make travel easy and rewarding for everyone.\n",
    "\n",
    " Get to Know our  Team: \n",
    "\n",
    "The Performance Marketing Team of Agoda is a world leader in online marketing. This department is highly data-driven and focused on developing at-scale marketing programs that improve the lifetime value of Agoda customers through measurable marketing programs and channels. The team is a blend of the best analysts, marketing strategists, and data scientists in the world. The marketing leadership at Agoda have deep experience in data science, product, strategy, and other marketing fields and have built an organization that thrives on data, creative ideas, and technology. The Performance Marketing Team also fosters a great learning environment. You will be able to learn and grow by working closely with experts from a variety of backgrounds from all over the world.\n",
    "\n",
    " In this Role, you’ll get  to: \n",
    "\n",
    "Search: Experiment with text ads, bidding, and campaign structures on Google, Bing, Baidu, Naver, and other search engines. Adapt to new product features and roll out changes from successful tests\n",
    "Display: Test, analyze, and optimize campaigns on Facebook, Twitter, Instagram, and others\n",
    "Modeling: Analyze the vast amounts of data generated by experiments, develop models we can use for optimization, and build dashboards for account managers\n",
    "\n",
    " What you’ll Need to  Succeed: \n",
    "\n",
    "Bachelor’s Degree or higher from top university in a quantitative subject (computer science, mathematics, engineering, statistics or science)\n",
    "Ability to communicate fluently in English\n",
    "Good numerical reasoning skills\n",
    "Proficiency in Excel\n",
    "Intellectual curiosity\n",
    "\n",
    " It’s Great if you  Have: \n",
    "\n",
    "Exposure to one or more data analysis packages or databases, e.g., SAS, R, SPSS, Python, VBA, SQL\n",
    "Experience in digital marketing\n",
    "Academic research experience\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "def job_gap(job_description):\n",
    "    llm = Ollama(\n",
    "        model='mistral:7b-instruct',\n",
    "        #model='llama2:chat',\n",
    "        #model='phi',\n",
    "        #model='falcon:instruct',\n",
    "        num_predict=4096,\n",
    "        temperature=0.8,\n",
    "        top_k=40,\n",
    "        )\n",
    "    \n",
    "    candidate_resume=\"\"\"\n",
    "    Agile Project Management: Experience with agile & waterfall hybrid project management using Jira and Confluence\n",
    "    Python: Familiar with Python data analysis and modeling using Scikit, Matlib, Plotty. Also have experience in using LLM framework Ollama, Langchain and Streamlit\n",
    "    Big Data and Data Visualization : Proficient in basic SQL, Snowflake, Bigquery, Spotfire and Tableau\n",
    "    Data Analysis: Familiar with data cleaning, hypothesis test (eg: Normality, ANOVA) and visualization using Python, JMP and Excel. Passionate in diving data set and exploration to extract data insights. Complete Google Data Analytics certification\n",
    "    Manufacturing Process Expert: Familiar in source of variation and factor correlation study for root cause finding and Measurement System Analysis (MSA)\n",
    "    Design of Experiment (DOE): Completed JMP Classical and Custom DOE courses. Certified as Company DOE Trainer\n",
    "    Kepner Tregoe (KT) Problem Solving: Complete KT training with a certified trainer, utilizing logical thinking and data analysis to analyze root cause and perform risk assessment\n",
    "    Microsoft Sharepoint: Owner of department collaboration site. Responsible for KPI reporting, project tracking, document permission & retention control\n",
    "    Microsoft Office: Expert in Microsoft Offices, include PowerPoint and Excel\n",
    "    Statiscal Process Control (SPC): Process SPC owner and FMEA champion\n",
    "    8D Problem Solving and Reporting: Experienced with 8D report requirements for internal and external customers\n",
    "    Semiconductor: More than 7 years exprience in Micron Semiconductor. Expert in Wire Bond(WB) process and Package Assembly. Held WB Process Engineer positions from HVM, NPI and TD. Collaborate with both internal product and business unit (BU) team and external key equipment group (KEG), OSAT and supplier (eg: wire, substrate) for new prodct development and reliability qualification\n",
    "    Stakeholder Communication and Management: Experience in collaboration with executives and crosss-functional teams. Provide project updata or data presentation to directos and vice presidents\n",
    "    Material Engineering: Bachelor of Materials Engineering with First Class Honours from Nanyang Technological University, Singapore\n",
    "    Finance: I have complete CFA Level 1 and currently I am candidate for Level 2\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_template=\"\"\"\"\n",
    "        You are job recruiter. You are performing job skill gap analysis of a job candidate step by step:\n",
    "        Step 1: Based on {job_description}, list down your job posiion name, company name, job responsibilities and job requirements,\n",
    "        Step 2: Based on {candidate_resume}, list down the candidate skills,\n",
    "        Step 3: Finaly, compare Step 1 and Step 2, and identify any skill gaps\n",
    "        \"\"\"\n",
    "    prompt_template = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "    chain =(prompt_template\n",
    "            |llm\n",
    "            |StrOutputParser()\n",
    "            )\n",
    "        \n",
    "    stream=chain.invoke(\n",
    "        {\"job_description\":job_description,\n",
    "         \"candidate_resume\":candidate_resume,}\n",
    "         )\n",
    "\n",
    "    text_file=open(docdir+'Job descriptions of opening position shared by Hiring Manager.txt','w')\n",
    "    text_file.write(stream)\n",
    "    text_file.close()\n",
    "    print(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the information provided in both steps, here is a comparison of the job position and requirements between being a Senior Data Analyst at Agoda and having various other skill sets:\n",
      "\n",
      "**Job Position:** Senior Data Analyst at Agoda\n",
      "\n",
      "**Company Name:** Agoda\n",
      "\n",
      "**Job Responsibilities:**\n",
      "- Search: Experiment with text ads, bidding, and campaign structures on search engines. Adapt to new product features and roll out changes from successful tests.\n",
      "- Display: Test, analyze, and optimize campaigns on social media platforms.\n",
      "- Modeling: Analyze data generated by experiments, develop models for optimization, and build dashboards for account managers.\n",
      "\n",
      "**Job Requirements:**\n",
      "- Bachelor's Degree or higher from a top university in a quantitative subject.\n",
      "- Fluent English communication skills.\n",
      "- Good numerical reasoning skills.\n",
      "- Proficiency in Excel.\n",
      "- Intellectual curiosity.\n",
      "\n",
      "**Candidate Skills (Step 2):**\n",
      "- Agile & waterfall hybrid project management using Jira and Confluence.\n",
      "- Python data analysis and modeling using Scikit, Matlib, Plotty, Ollama, Langchain, and Streamlit.\n",
      "- Basic SQL, Snowflake, Bigquery, Spotfire, and Tableau for big data and data visualization.\n",
      "- Data cleaning, hypothesis testing (e.g., Normality, ANOVA), and visualization using Python, JMP, and Excel.\n",
      "- Google Data Analytics certification.\n",
      "- Familiarity with manufacturing process expert, design of experiments, Kepner Tregoe problem solving, Microsoft Sharepoint, and Statistical Process Control.\n",
      "- Experience in semiconductor, stakeholder communication and management, material engineering, and finance.\n",
      "\n",
      "**Skill Gaps:**\n",
      "The candidate in Step 2 has a broader set of skills than the Senior Data Analyst role at Agoda. Some potential skill gaps include:\n",
      "\n",
      "1. Digital marketing experience or exposure, which is directly mentioned in the Senior Data Analyst job description.\n",
      "2. Specific data analysis packages or databases (SAS, R, SPSS, VBA, SQL) that are not explicitly required but might be beneficial for the role.\n",
      "3. Knowledge of Agoda's unique marketing technologies and tools used by their Performance Marketing Team (not mentioned in Step 2).\n",
      "4. Familiarity with Agoda's purpose, mission, and company culture.\n",
      "5. Experience or knowledge in online travel booking platforms, which could be important for understanding the context and use cases of the data being analyzed.\n"
     ]
    }
   ],
   "source": [
    "job_gap(job_description)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
